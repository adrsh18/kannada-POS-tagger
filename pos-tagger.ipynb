{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kannada POS Tagger using Linear Chain CRF\n",
    "\n",
    "We will now train and tag the words using the features extracted from Word2Vec in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the word features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.load(\"kannada-features.numpy\").astype(np.float32)\n",
    "Y = np.load(\"kannada-labels.numpy\").astype(np.int32)\n",
    "\n",
    "np.random.seed(546)\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "Y = Y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each sentence has varying number of words. So, we need to determine sequence lengths before hand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_examples, num_words, num_features = X.shape\n",
    "num_tags = np.unique(Y).size\n",
    "\n",
    "sequence_lengths = np.full(num_examples, 0, dtype=np.int32)\n",
    "for idx, row in enumerate(X):\n",
    "    count = 0\n",
    "    for word in row:\n",
    "        if np.all(word == -1):\n",
    "            break\n",
    "        count += 1\n",
    "    sequence_lengths[idx] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split = 100\n",
    "x_test = X[-split:,:,:]\n",
    "y_test = Y[-split:,:]\n",
    "s_test = sequence_lengths[-split:]\n",
    "\n",
    "x = X[0:-split,:,:]\n",
    "y = Y[0:-split,:]\n",
    "sequence_lengths = sequence_lengths[0:-split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on Linear Chain CRF\n",
    "\n",
    "Tensorflow kinda makes it all easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy (Training set):  5.61625455242\n",
      "Classification Accuracy (Training set):  58.8269120184\n",
      "Classification Accuracy (Training set):  61.5487828254\n",
      "Classification Accuracy (Training set):  66.9541882308\n",
      "Classification Accuracy (Training set):  67.0308606479\n",
      "Classification Accuracy (Training set):  69.7335633506\n",
      "Classification Accuracy (Training set):  70.1169254361\n",
      "Classification Accuracy (Training set):  71.4970289438\n",
      "Classification Accuracy (Training set):  71.7270461951\n",
      "Classification Accuracy (Training set):  72.5321065747\n",
      "Classification Accuracy (Training set):  73.1071497029\n",
      "Classification Accuracy (Training set):  73.5671842055\n",
      "Classification Accuracy (Training set):  73.8738738739\n",
      "Classification Accuracy (Training set):  74.3339083765\n",
      "Classification Accuracy (Training set):  74.583093732\n",
      "Classification Accuracy (Training set):  74.6981023577\n",
      "Classification Accuracy (Training set):  75.0239601303\n",
      "Classification Accuracy (Training set):  75.2923135902\n",
      "Classification Accuracy (Training set):  75.4456584244\n",
      "Classification Accuracy (Training set):  75.6373394671\n",
      "-------------------------------------------------\n",
      "Classification Accuracy (Test set):  66.1714285714\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as session:\n",
    "        x_t = tf.constant(x)\n",
    "        xt_t = tf.constant(x_test)\n",
    "        y_t = tf.constant(y)\n",
    "        yt_t = tf.constant(y_test)\n",
    "        sequence_lengths_t = tf.constant(sequence_lengths)\n",
    "        st_t = tf.constant(s_test)\n",
    "        \n",
    "        weights = tf.get_variable(\"weights\", [num_features, num_tags])\n",
    "        matricized_x_t = tf.reshape(x_t, [-1, num_features])\n",
    "        matricized_unary_scores = tf.matmul(matricized_x_t, weights)\n",
    "        unary_scores = tf.reshape(matricized_unary_scores, [num_examples-split, num_words, num_tags])\n",
    "        \n",
    "        matricized_xt_t = tf.reshape(xt_t, [-1, num_features])\n",
    "        matricized_ust = tf.matmul(matricized_xt_t, weights)\n",
    "        ust = tf.reshape(matricized_ust, [split, num_words, num_tags])\n",
    "        \n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(unary_scores, y_t, sequence_lengths_t)\n",
    "        \n",
    "        loss = tf.reduce_mean(-log_likelihood)\n",
    "        train_op = tf.train.GradientDescentOptimizer(0.03).minimize(loss)\n",
    "        \n",
    "        session.run(tf.global_variables_initializer())\n",
    "        for i in range(100):\n",
    "            tf_ust, tf_unary_scores, tf_transition_params, _ = session.run([ust, unary_scores, transition_params, train_op])\n",
    "            if i%5 == 0:\n",
    "                correct_labels = 0\n",
    "                total_labels = 0\n",
    "                for tf_unary_scores_, y_, sequence_length_ in zip(tf_unary_scores, y, sequence_lengths):\n",
    "                    tf_unary_scores_ = tf_unary_scores_[:sequence_length_]\n",
    "                    y_ = y_[:sequence_length_]\n",
    "                    \n",
    "                    viterbi_sequence, _ = tf.contrib.crf.viterbi_decode(tf_unary_scores_, tf_transition_params)\n",
    "                    \n",
    "                    correct_labels += np.sum(np.equal(viterbi_sequence, y_))\n",
    "                    total_labels += sequence_length_\n",
    "                accuracy = 100.0 * correct_labels / float(total_labels)\n",
    "                print \"Classification Accuracy (Training set): \", accuracy\n",
    "        correct_labels = 0\n",
    "        total_labels = 0\n",
    "        pred_labels = []\n",
    "        actual_labels = []\n",
    "        for a, b, c in zip(tf_ust, y_test, s_test):\n",
    "            a = a[:c]\n",
    "            b = b[:c]\n",
    "            \n",
    "            vs, _ = tf.contrib.crf.viterbi_decode(a, tf_transition_params)\n",
    "            correct_labels += np.sum(np.equal(vs, b))\n",
    "            total_labels += c\n",
    "            \n",
    "            actual_labels = actual_labels + b.tolist()\n",
    "            pred_labels = pred_labels + vs\n",
    "            \n",
    "        accuracy = 100.0 * correct_labels / float(total_labels)\n",
    "        print \"-------------------------------------------------\"\n",
    "        print \"Classification Accuracy (Test set): \", accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation - Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         CC       0.90      0.60      0.72        15\n",
      "        DEM       0.85      0.65      0.73        17\n",
      "        DET       0.00      0.00      0.00        12\n",
      "         JJ       0.14      0.08      0.10        49\n",
      "         NN       0.60      0.78      0.68       306\n",
      "        NUM       0.00      0.00      0.00         2\n",
      "        PRP       0.74      0.58      0.65       110\n",
      "        PSP       0.80      0.29      0.42        14\n",
      "         QC       0.69      0.45      0.55        20\n",
      "         RB       0.74      0.30      0.43        46\n",
      "        SYM       0.99      0.99      0.99        83\n",
      "         UT       1.00      0.89      0.94         9\n",
      "         VM       0.64      0.72      0.67       190\n",
      "         WQ       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.65      0.66      0.64       875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarsh/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = np.array(['CC', 'DEM', 'DET', 'INJ', 'IRR', 'JJ', 'NN', 'NUM', 'PRP', 'PSP',\n",
    "       'QC', 'RB', 'SYM', 'UT', 'VM', 'WQ'])\n",
    "\n",
    "print classification_report(actual_labels, pred_labels, target_names=target_names[np.unique(actual_labels)].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
