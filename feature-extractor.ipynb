{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction from Kannada Words\n",
    "\n",
    "The language Kannada has a rather complicated script. Our usual choice of features such as uppercase, lowercase, isdigit, prefix, suffix etc., would not work on such a language. Hence, we need a better way to extract features these words. \n",
    "\n",
    "My choice was **Word2Vec**\n",
    "\n",
    "This script:\n",
    "1. Parses and structures the corpus file into sentences.\n",
    "2. Builds a Word2Vec Model (using gensim)\n",
    "3. Creates a Vocabulary from the corpus (using gensim).\n",
    "4. Trains the Word2Vec Model on the sentences from (1).\n",
    "5. Extracts and saves the word vectors from the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = codecs.open(\"corpus.txt\", \"r\", encoding=\"utf8\")\n",
    "\n",
    "raw = f.readlines()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the long list of words into sentences and decoding from UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "l = []\n",
    "\n",
    "for w in raw:\n",
    "    w = w.encode('utf-8')\n",
    "    x = w.strip(b'\\n').split(b' ')\n",
    "    if x[0] == b'*' or x[0] == b'.' or len(x) < 2:\n",
    "        if len(l) > 0:\n",
    "            lines.append(l)\n",
    "        l = []\n",
    "        continue\n",
    "    l.append((x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "num_words = 0\n",
    "\n",
    "for l in lines:\n",
    "    s = []\n",
    "    lab = []\n",
    "    for w in l:\n",
    "        x = w[0].decode('utf-8')\n",
    "        y = w[1].decode('utf-8')\n",
    "        s.append(x)\n",
    "        num_words += 1\n",
    "        lab.append(y)\n",
    "    labels.append(lab)\n",
    "    sentences.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Word2Vec model and build vocabulary from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_count = 1\n",
    "size = 100\n",
    "window = 20\n",
    "\n",
    "model = Word2Vec(window=window, min_count=min_count, size=size)\n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model on the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "Iteration  100\n",
      "Iteration  200\n",
      "Iteration  300\n",
      "Iteration  400\n",
      "Iteration  500\n",
      "Iteration  600\n",
      "Iteration  700\n",
      "Iteration  800\n",
      "Iteration  900\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    model.train(sentences, total_words=num_words, epochs=1)\n",
    "    if i%100 == 0:\n",
    "        print(\"Iteration \",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract vectors from the trained model and generate features\n",
    "\n",
    "Features of current word includes features of neighboring words in a 3-word-window to provide context for Linear Chain CRF. Thus avoiding the need to add additional hidden units in our CRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for idx,s in enumerate(sentences):\n",
    "    x = []\n",
    "    yy = []\n",
    "    for wi,w in enumerate(s):\n",
    "        if w in model:\n",
    "            m = model[w]\n",
    "            if wi > 1:\n",
    "                m = np.hstack([m,model[s[wi-1]]])\n",
    "            else:\n",
    "                m = np.hstack([m,np.zeros_like(model[w])])\n",
    "            \n",
    "            if wi > 2:\n",
    "                m = np.hstack([m,model[s[wi-2]]])\n",
    "            else:\n",
    "                m = np.hstack([m,np.zeros_like(model[w])])\n",
    "            \n",
    "            if wi > 3:\n",
    "                m = np.hstack([m,model[s[wi-3]]])\n",
    "            else:\n",
    "                m = np.hstack([m,np.zeros_like(model[w])])\n",
    "            \n",
    "            if wi < len(s)-1:\n",
    "                m = np.hstack([m,model[s[wi+1]]])\n",
    "            else:\n",
    "                m = np.hstack([m,np.zeros_like(model[w])])\n",
    "            \n",
    "            if wi < len(s)-2:\n",
    "                m = np.hstack([m,model[s[wi+2]]])\n",
    "            else:\n",
    "                m = np.hstack([m,np.zeros_like(model[w])])\n",
    "            \n",
    "            if wi < len(s)-3:\n",
    "                m = np.hstack([m,model[s[wi+3]]])\n",
    "            else:\n",
    "                m = np.hstack([m,np.zeros_like(model[w])])\n",
    "            x.append(m)\n",
    "    offset = 100 - len(x)\n",
    "    pad_x = np.zeros_like(model[w]) - 1\n",
    "    pad_x = np.hstack([pad_x,pad_x,pad_x,pad_x,pad_x, pad_x, pad_x])\n",
    "    yy = yy + labels[idx]\n",
    "    for i in range(offset):\n",
    "        x.append(pad_x)\n",
    "        yy.append(\"IRR\")\n",
    "        #print(idx,\" \",m)\n",
    "        #print(m)\n",
    "    X.append(x)\n",
    "    y.append(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CC', 'DEM', 'DET', 'INJ', 'IRR', 'JJ', 'NN', 'NUM', 'PRP', 'PSP',\n",
       "       'QC', 'RB', 'SYM', 'UT', 'VM', 'WQ'], \n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_shape = y.shape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y.ravel()).reshape(original_shape)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the feature and label vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"kannada-features.numpy\", \"wb\")\n",
    "np.save(f, X)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"kannada-labels.numpy\", \"wb\")\n",
    "np.save(f,y)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
